{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mysql-connector-python in ./.venv/lib/python3.12/site-packages (9.0.0)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (2.1.1)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.12/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (2.1.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n"
     ]
    }
   ],
   "source": [
    "! pip install mysql-connector-python\n",
    "! pip install numpy\n",
    "! pip install scikit-learn\n",
    "! pip install python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "#import dotenv and use it to load the environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "# Connect to MySQL\n",
    "db_host = os.getenv(\"DB_HOST\")\n",
    "db_port = os.getenv(\"DB_PORT\")\n",
    "db_name = os.getenv(\"DB_DATABASE\")\n",
    "db_user = os.getenv(\"DB_USERNAME\")\n",
    "db_password = os.getenv(\"DB_PASSWORD\")\n",
    "\n",
    "# Connect to MySQL using the loaded environment variables\n",
    "db = mysql.connector.connect(\n",
    "    host=db_host,\n",
    "    port=db_port,\n",
    "    database=db_name,\n",
    "    user=db_user,\n",
    "    password=db_password\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Fetch all vectors in memory\u001b[39;00m\n\u001b[1;32m     21\u001b[0m cursor\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT id, normalized_vector FROM vectors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m vectors \u001b[38;5;241m=\u001b[39m \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetchall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Process vectors in chunks\u001b[39;00m\n\u001b[1;32m     25\u001b[0m chunk_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n",
      "File \u001b[0;32m~/Documents/grantSiteAI/grants-app-stage/.venv/lib/python3.12/site-packages/mysql/connector/cursor_cext.py:642\u001b[0m, in \u001b[0;36mCMySQLCursor.fetchall\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39munread_result:\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[0;32m--> 642\u001b[0m rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_rows\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nextrow \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nextrow[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m    644\u001b[0m     rows[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nextrow[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/Documents/grantSiteAI/grants-app-stage/.venv/lib/python3.12/site-packages/mysql/connector/connection_cext.py:514\u001b[0m, in \u001b[0;36mCMySQLConnection.get_rows\u001b[0;34m(self, count, binary, columns, raw, prep_stmt)\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m count \u001b[38;5;129;01mand\u001b[39;00m counter \u001b[38;5;241m==\u001b[39m count:\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 514\u001b[0m     row \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m row:\n\u001b[1;32m    516\u001b[0m     _eof: Optional[CextEofPacketType] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfetch_eof_columns(prep_stmt)[\n\u001b[1;32m    517\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meof\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    518\u001b[0m     ]  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import numpy as np\n",
    "import logging\n",
    "import json  # Add json to handle JSON conversion\n",
    "\n",
    "# Setup logging to log to the notebook and a file\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "cursor = db.cursor()\n",
    "\n",
    "# Fetch normalized vectors\n",
    "cursor.execute(\"SELECT normalized_vector FROM vectors\")\n",
    "\n",
    "vectors = []\n",
    "for idx, v in enumerate(cursor.fetchall()):\n",
    "    try:\n",
    "        # Log progress in Jupyter\n",
    "        if idx % 1000 == 0:\n",
    "            print(f\"Processing vector {idx}...\")\n",
    "\n",
    "        # Remove any brackets and whitespace, then split the string by commas\n",
    "        cleaned_vector = v[0].replace('[', '').replace(']', '').strip()\n",
    "        vector = np.array(list(map(float, cleaned_vector.split(','))))\n",
    "        vectors.append(vector)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error converting vector at index {idx}: {v[0]}\")\n",
    "        logging.error(f\"Error converting vector at index {idx}: {v[0]}\")\n",
    "        logging.exception(e)\n",
    "\n",
    "# Convert to a NumPy array\n",
    "vectors = np.array(vectors)\n",
    "\n",
    "# Log the number of valid vectors\n",
    "print(f\"Successfully fetched and parsed {len(vectors)} vectors.\")\n",
    "logging.info(f\"Successfully fetched and parsed {len(vectors)} vectors.\")\n",
    "\n",
    "# Run k-means\n",
    "print(\"Starting K-means clustering...\")\n",
    "num_centroids = 200\n",
    "kmeans = KMeans(n_clusters=num_centroids, max_iter=100, random_state=0)\n",
    "kmeans.fit(vectors)\n",
    "\n",
    "# Log centroids creation completion\n",
    "print(f\"K-means clustering completed. Found {len(kmeans.cluster_centers_)} centroids.\")\n",
    "logging.info(f\"K-means clustering completed. Found {len(kmeans.cluster_centers_)} centroids.\")\n",
    "\n",
    "# Save centroids back to the database\n",
    "centroids = kmeans.cluster_centers_\n",
    "for index, centroid in enumerate(centroids):\n",
    "    centroid_json = json.dumps(centroid.tolist())  # Convert the NumPy array to a list and then to JSON\n",
    "    \n",
    "    # First, check if the centroid with the given ID exists\n",
    "    cursor.execute(\"SELECT id FROM centroids WHERE id = %s\", (index + 1,))\n",
    "    result = cursor.fetchone()\n",
    "\n",
    "    if result:\n",
    "        # If the centroid exists, update it\n",
    "        cursor.execute(\n",
    "            \"UPDATE centroids SET vector = %s WHERE id = %s\", \n",
    "            (centroid_json, index + 1)\n",
    "        )\n",
    "        logging.info(f\"Updated Centroid {index + 1} in the database.\")\n",
    "    else:\n",
    "        # If the centroid doesn't exist, insert it\n",
    "        cursor.execute(\n",
    "            \"INSERT INTO centroids (id, vector) VALUES (%s, %s)\", \n",
    "            (index + 1, centroid_json)\n",
    "        )\n",
    "        logging.info(f\"Inserted new Centroid {index + 1} into the database.\")\n",
    "\n",
    "db.commit()\n",
    "cursor.close()\n",
    "db.close()\n",
    "\n",
    "print(\"Centroid processing completed successfully.\")\n",
    "logging.info(\"Centroid processing completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 22:38:08,656 - INFO - Total vectors to process: 78389\n",
      "2024-10-03 22:38:08,664 - INFO - Processed 100 out of 78389 vectors\n",
      "2024-10-03 22:38:30,908 - INFO - Processed 200 out of 78389 vectors\n",
      "2024-10-03 22:38:39,378 - INFO - Processed 300 out of 78389 vectors\n",
      "2024-10-03 22:38:47,736 - INFO - Processed 400 out of 78389 vectors\n",
      "2024-10-03 22:38:56,133 - INFO - Processed 500 out of 78389 vectors\n",
      "2024-10-03 22:39:04,515 - INFO - Processed 600 out of 78389 vectors\n",
      "2024-10-03 22:39:12,889 - INFO - Processed 700 out of 78389 vectors\n",
      "2024-10-03 22:39:21,293 - INFO - Processed 800 out of 78389 vectors\n",
      "2024-10-03 22:39:29,662 - INFO - Processed 900 out of 78389 vectors\n",
      "2024-10-03 22:39:38,249 - INFO - Processed 1000 out of 78389 vectors\n",
      "2024-10-03 22:39:46,619 - INFO - Processed 1100 out of 78389 vectors\n",
      "2024-10-03 22:39:54,964 - INFO - Processed 1200 out of 78389 vectors\n",
      "2024-10-03 22:40:03,281 - INFO - Processed 1300 out of 78389 vectors\n",
      "2024-10-03 22:40:11,600 - INFO - Processed 1400 out of 78389 vectors\n",
      "2024-10-03 22:40:19,943 - INFO - Processed 1500 out of 78389 vectors\n",
      "2024-10-03 22:40:28,601 - INFO - Processed 1600 out of 78389 vectors\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 63\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Perform bulk updates in batches of 100\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(updates) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecutemany\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUPDATE grant_vector SET centroid_id = \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m WHERE vector_id = \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43mupdates\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     db\u001b[38;5;241m.\u001b[39mcommit()\n\u001b[1;32m     68\u001b[0m     updates\u001b[38;5;241m.\u001b[39mclear()\n",
      "File \u001b[0;32m~/Documents/grantSiteAI/grants-app-stage/.venv/lib/python3.12/site-packages/mysql/connector/cursor_cext.py:494\u001b[0m, in \u001b[0;36mCMySQLCursor.executemany\u001b[0;34m(self, operation, seq_params)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;66;03m# When processing read ops (e.g., SELECT), rowcnt is updated\u001b[39;00m\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;66;03m# based on self._rowcount. For write ops (e.g., INSERT) is\u001b[39;00m\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;66;03m# updated based on self._affected_rows.\u001b[39;00m\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;66;03m# The variable self._description is None for write ops, that's\u001b[39;00m\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;66;03m# why we use it as indicator for updating rowcnt.\u001b[39;00m\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m params \u001b[38;5;129;01min\u001b[39;00m seq_params:\n\u001b[0;32m--> 494\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    495\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_rows \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39munread_result:\n\u001b[1;32m    496\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfetchall()\n",
      "File \u001b[0;32m~/Documents/grantSiteAI/grants-app-stage/.venv/lib/python3.12/site-packages/mysql/connector/cursor_cext.py:357\u001b[0m, in \u001b[0;36mCMySQLCursor.execute\u001b[0;34m(self, operation, params, multi)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m ProgrammingError(\n\u001b[1;32m    353\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot all parameters were used in the SQL statement\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    354\u001b[0m             )\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 357\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcmd_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuffered\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffered\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_as_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_as_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MySQLInterfaceError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m get_mysql_exception(\n\u001b[1;32m    365\u001b[0m         msg\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39mmsg, errno\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39merrno, sqlstate\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39msqlstate\n\u001b[1;32m    366\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/grantSiteAI/grants-app-stage/.venv/lib/python3.12/site-packages/mysql/connector/opentelemetry/context_propagation.py:97\u001b[0m, in \u001b[0;36mwith_context_propagation.<locals>.wrapper\u001b[0;34m(cnx, *args, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# pylint: disable=possibly-used-before-assignment\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m OTEL_ENABLED \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cnx\u001b[38;5;241m.\u001b[39motel_context_propagation:\n\u001b[0;32m---> 97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcnx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m current_span \u001b[38;5;241m=\u001b[39m trace\u001b[38;5;241m.\u001b[39mget_current_span()\n\u001b[1;32m    100\u001b[0m tp_header \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/grantSiteAI/grants-app-stage/.venv/lib/python3.12/site-packages/mysql/connector/connection_cext.py:705\u001b[0m, in \u001b[0;36mCMySQLConnection.cmd_query\u001b[0;34m(self, query, raw, buffered, raw_as_string)\u001b[0m\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(query, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m    704\u001b[0m         query \u001b[38;5;241m=\u001b[39m query\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 705\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmysql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuffered\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffered\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_as_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_as_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MySQLInterfaceError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m get_mysql_exception(\n\u001b[1;32m    714\u001b[0m         err\u001b[38;5;241m.\u001b[39merrno, msg\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39mmsg, sqlstate\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39msqlstate\n\u001b[1;32m    715\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import numpy as np\n",
    "import logging\n",
    "import json\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Assuming db connection is already established\n",
    "cursor = db.cursor()\n",
    "\n",
    "# Fetch centroids from the database\n",
    "cursor.execute(\"SELECT id, vector FROM centroids\")\n",
    "centroids = cursor.fetchall()\n",
    "\n",
    "# Convert centroids into NumPy arrays\n",
    "centroid_ids = [c[0] for c in centroids]\n",
    "centroid_vectors = np.array([np.array(json.loads(c[1])) for c in centroids])\n",
    "\n",
    "# Fetch all vectors in memory\n",
    "cursor.execute(\"SELECT id, normalized_vector FROM vectors\")\n",
    "vectors = cursor.fetchall()\n",
    "\n",
    "# Process vectors in chunks\n",
    "chunk_size = 100\n",
    "total_vectors = len(vectors)\n",
    "logging.info(f\"Total vectors to process: {total_vectors}\")\n",
    "\n",
    "processed_count = 0\n",
    "updates = []  # Collect updates to perform bulk updates\n",
    "\n",
    "# Normalize centroids (if not already normalized in your data)\n",
    "centroid_magnitudes = np.linalg.norm(centroid_vectors, axis=1)\n",
    "\n",
    "for i in range(0, total_vectors, chunk_size):\n",
    "    chunk = vectors[i:i + chunk_size]\n",
    "\n",
    "    # Extract vector data and convert to NumPy\n",
    "    vector_ids = [v[0] for v in chunk]\n",
    "    vector_data = np.array([np.array(json.loads(v[1])) for v in chunk])\n",
    "\n",
    "    # Normalize vectors (assuming normalized_vector is not already normalized)\n",
    "    vector_magnitudes = np.linalg.norm(vector_data, axis=1)\n",
    "\n",
    "    # Perform bulk cosine similarity calculation\n",
    "    dot_products = np.dot(vector_data, centroid_vectors.T)\n",
    "    cosine_similarities = dot_products / (vector_magnitudes[:, None] * centroid_magnitudes)\n",
    "\n",
    "    # Get the index of the closest centroid for each vector\n",
    "    best_matches = np.argmax(cosine_similarities, axis=1)\n",
    "    \n",
    "    # Prepare updates for batch execution\n",
    "    for idx, best_match_idx in enumerate(best_matches):\n",
    "        best_centroid_id = centroid_ids[best_match_idx]\n",
    "        vector_id = vector_ids[idx]\n",
    "        updates.append((best_centroid_id, vector_id))\n",
    "\n",
    "    processed_count += len(chunk)\n",
    "    logging.info(f\"Processed {processed_count} out of {total_vectors} vectors\")\n",
    "\n",
    "    # Perform bulk updates in batches of 100\n",
    "    if len(updates) >= 100:\n",
    "        cursor.executemany(\n",
    "            \"UPDATE grant_vector SET centroid_id = %s WHERE vector_id = %s\",\n",
    "            updates\n",
    "        )\n",
    "        db.commit()\n",
    "        updates.clear()\n",
    "\n",
    "# Perform remaining updates if any\n",
    "if updates:\n",
    "    cursor.executemany(\n",
    "        \"UPDATE grant_vector SET centroid_id = %s WHERE vector_id = %s\",\n",
    "        updates\n",
    "    )\n",
    "    db.commit()\n",
    "\n",
    "# Commit the changes and close the connection\n",
    "cursor.close()\n",
    "db.close()\n",
    "\n",
    "logging.info(\"Centroid assignment for vectors completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 22:41:15,354 - INFO - Total vectors to process: 78389\n",
      "2024-10-03 22:41:15,398 - INFO - Processed 500 out of 78389 vectors\n",
      "2024-10-03 22:41:15,623 - INFO - Processed 1000 out of 78389 vectors\n",
      "2024-10-03 22:41:15,843 - INFO - Processed 1500 out of 78389 vectors\n",
      "2024-10-03 22:41:16,059 - INFO - Processed 2000 out of 78389 vectors\n",
      "2024-10-03 22:41:16,271 - INFO - Processed 2500 out of 78389 vectors\n",
      "2024-10-03 22:41:16,488 - INFO - Processed 3000 out of 78389 vectors\n",
      "2024-10-03 22:41:16,717 - INFO - Processed 3500 out of 78389 vectors\n",
      "2024-10-03 22:41:16,949 - INFO - Processed 4000 out of 78389 vectors\n",
      "2024-10-03 22:41:17,172 - INFO - Processed 4500 out of 78389 vectors\n",
      "2024-10-03 22:41:17,379 - INFO - Processed 5000 out of 78389 vectors\n",
      "2024-10-03 22:41:17,608 - INFO - Processed 5500 out of 78389 vectors\n",
      "2024-10-03 22:41:17,817 - INFO - Processed 6000 out of 78389 vectors\n",
      "2024-10-03 22:41:18,044 - INFO - Processed 6500 out of 78389 vectors\n",
      "2024-10-03 22:41:18,261 - INFO - Processed 7000 out of 78389 vectors\n",
      "2024-10-03 22:41:18,489 - INFO - Processed 7500 out of 78389 vectors\n",
      "2024-10-03 22:41:18,703 - INFO - Processed 8000 out of 78389 vectors\n",
      "2024-10-03 22:41:18,917 - INFO - Processed 8500 out of 78389 vectors\n",
      "2024-10-03 22:41:19,133 - INFO - Processed 9000 out of 78389 vectors\n",
      "2024-10-03 22:41:19,362 - INFO - Processed 9500 out of 78389 vectors\n",
      "2024-10-03 22:41:19,589 - INFO - Processed 10000 out of 78389 vectors\n",
      "2024-10-03 22:41:19,819 - INFO - Processed 10500 out of 78389 vectors\n",
      "2024-10-03 22:41:20,040 - INFO - Processed 11000 out of 78389 vectors\n",
      "2024-10-03 22:41:20,260 - INFO - Processed 11500 out of 78389 vectors\n",
      "2024-10-03 22:41:20,483 - INFO - Processed 12000 out of 78389 vectors\n",
      "2024-10-03 22:41:20,704 - INFO - Processed 12500 out of 78389 vectors\n",
      "2024-10-03 22:41:20,919 - INFO - Processed 13000 out of 78389 vectors\n",
      "2024-10-03 22:41:21,134 - INFO - Processed 13500 out of 78389 vectors\n",
      "2024-10-03 22:41:21,354 - INFO - Processed 14000 out of 78389 vectors\n",
      "2024-10-03 22:41:21,574 - INFO - Processed 14500 out of 78389 vectors\n",
      "2024-10-03 22:41:21,795 - INFO - Processed 15000 out of 78389 vectors\n",
      "2024-10-03 22:41:22,027 - INFO - Processed 15500 out of 78389 vectors\n",
      "2024-10-03 22:41:22,246 - INFO - Processed 16000 out of 78389 vectors\n",
      "2024-10-03 22:41:22,467 - INFO - Processed 16500 out of 78389 vectors\n",
      "2024-10-03 22:41:22,686 - INFO - Processed 17000 out of 78389 vectors\n",
      "2024-10-03 22:41:22,898 - INFO - Processed 17500 out of 78389 vectors\n",
      "2024-10-03 22:41:23,122 - INFO - Processed 18000 out of 78389 vectors\n",
      "2024-10-03 22:41:23,334 - INFO - Processed 18500 out of 78389 vectors\n",
      "2024-10-03 22:41:23,549 - INFO - Processed 19000 out of 78389 vectors\n",
      "2024-10-03 22:41:23,766 - INFO - Processed 19500 out of 78389 vectors\n",
      "2024-10-03 22:41:23,991 - INFO - Processed 20000 out of 78389 vectors\n",
      "2024-10-03 22:41:24,208 - INFO - Processed 20500 out of 78389 vectors\n",
      "2024-10-03 22:41:24,417 - INFO - Processed 21000 out of 78389 vectors\n",
      "2024-10-03 22:41:24,640 - INFO - Processed 21500 out of 78389 vectors\n",
      "2024-10-03 22:41:24,856 - INFO - Processed 22000 out of 78389 vectors\n",
      "2024-10-03 22:41:25,099 - INFO - Processed 22500 out of 78389 vectors\n",
      "2024-10-03 22:41:25,314 - INFO - Processed 23000 out of 78389 vectors\n",
      "2024-10-03 22:41:25,546 - INFO - Processed 23500 out of 78389 vectors\n",
      "2024-10-03 22:41:25,766 - INFO - Processed 24000 out of 78389 vectors\n",
      "2024-10-03 22:41:25,985 - INFO - Processed 24500 out of 78389 vectors\n",
      "2024-10-03 22:41:26,200 - INFO - Processed 25000 out of 78389 vectors\n",
      "2024-10-03 22:41:26,429 - INFO - Processed 25500 out of 78389 vectors\n",
      "2024-10-03 22:41:26,652 - INFO - Processed 26000 out of 78389 vectors\n",
      "2024-10-03 22:41:26,882 - INFO - Processed 26500 out of 78389 vectors\n",
      "2024-10-03 22:41:27,123 - INFO - Processed 27000 out of 78389 vectors\n",
      "2024-10-03 22:41:27,344 - INFO - Processed 27500 out of 78389 vectors\n",
      "2024-10-03 22:41:27,564 - INFO - Processed 28000 out of 78389 vectors\n",
      "2024-10-03 22:41:27,776 - INFO - Processed 28500 out of 78389 vectors\n",
      "2024-10-03 22:41:27,995 - INFO - Processed 29000 out of 78389 vectors\n",
      "2024-10-03 22:41:28,224 - INFO - Processed 29500 out of 78389 vectors\n",
      "2024-10-03 22:41:28,440 - INFO - Processed 30000 out of 78389 vectors\n",
      "2024-10-03 22:41:28,657 - INFO - Processed 30500 out of 78389 vectors\n",
      "2024-10-03 22:41:28,887 - INFO - Processed 31000 out of 78389 vectors\n",
      "2024-10-03 22:41:29,099 - INFO - Processed 31500 out of 78389 vectors\n",
      "2024-10-03 22:41:29,318 - INFO - Processed 32000 out of 78389 vectors\n",
      "2024-10-03 22:41:29,541 - INFO - Processed 32500 out of 78389 vectors\n",
      "2024-10-03 22:41:29,769 - INFO - Processed 33000 out of 78389 vectors\n",
      "2024-10-03 22:41:29,986 - INFO - Processed 33500 out of 78389 vectors\n",
      "2024-10-03 22:41:30,225 - INFO - Processed 34000 out of 78389 vectors\n",
      "2024-10-03 22:41:30,439 - INFO - Processed 34500 out of 78389 vectors\n",
      "2024-10-03 22:41:30,657 - INFO - Processed 35000 out of 78389 vectors\n",
      "2024-10-03 22:41:30,881 - INFO - Processed 35500 out of 78389 vectors\n",
      "2024-10-03 22:41:31,094 - INFO - Processed 36000 out of 78389 vectors\n",
      "2024-10-03 22:41:31,309 - INFO - Processed 36500 out of 78389 vectors\n",
      "2024-10-03 22:41:31,547 - INFO - Processed 37000 out of 78389 vectors\n",
      "2024-10-03 22:41:31,793 - INFO - Processed 37500 out of 78389 vectors\n",
      "2024-10-03 22:41:32,014 - INFO - Processed 38000 out of 78389 vectors\n",
      "2024-10-03 22:41:32,238 - INFO - Processed 38500 out of 78389 vectors\n",
      "2024-10-03 22:41:32,458 - INFO - Processed 39000 out of 78389 vectors\n",
      "2024-10-03 22:41:32,681 - INFO - Processed 39500 out of 78389 vectors\n",
      "2024-10-03 22:41:32,902 - INFO - Processed 40000 out of 78389 vectors\n",
      "2024-10-03 22:41:33,123 - INFO - Processed 40500 out of 78389 vectors\n",
      "2024-10-03 22:41:33,344 - INFO - Processed 41000 out of 78389 vectors\n",
      "2024-10-03 22:41:33,572 - INFO - Processed 41500 out of 78389 vectors\n",
      "2024-10-03 22:41:33,787 - INFO - Processed 42000 out of 78389 vectors\n",
      "2024-10-03 22:41:34,012 - INFO - Processed 42500 out of 78389 vectors\n",
      "2024-10-03 22:41:34,240 - INFO - Processed 43000 out of 78389 vectors\n",
      "2024-10-03 22:41:34,453 - INFO - Processed 43500 out of 78389 vectors\n",
      "2024-10-03 22:41:34,676 - INFO - Processed 44000 out of 78389 vectors\n",
      "2024-10-03 22:41:34,889 - INFO - Processed 44500 out of 78389 vectors\n",
      "2024-10-03 22:41:35,111 - INFO - Processed 45000 out of 78389 vectors\n",
      "2024-10-03 22:41:35,326 - INFO - Processed 45500 out of 78389 vectors\n",
      "2024-10-03 22:41:35,544 - INFO - Processed 46000 out of 78389 vectors\n",
      "2024-10-03 22:41:35,767 - INFO - Processed 46500 out of 78389 vectors\n",
      "2024-10-03 22:41:35,982 - INFO - Processed 47000 out of 78389 vectors\n",
      "2024-10-03 22:41:36,208 - INFO - Processed 47500 out of 78389 vectors\n",
      "2024-10-03 22:41:36,424 - INFO - Processed 48000 out of 78389 vectors\n",
      "2024-10-03 22:41:36,640 - INFO - Processed 48500 out of 78389 vectors\n",
      "2024-10-03 22:41:36,855 - INFO - Processed 49000 out of 78389 vectors\n",
      "2024-10-03 22:41:37,071 - INFO - Processed 49500 out of 78389 vectors\n",
      "2024-10-03 22:41:37,291 - INFO - Processed 50000 out of 78389 vectors\n",
      "2024-10-03 22:41:37,506 - INFO - Processed 50500 out of 78389 vectors\n",
      "2024-10-03 22:41:37,721 - INFO - Processed 51000 out of 78389 vectors\n",
      "2024-10-03 22:41:37,938 - INFO - Processed 51500 out of 78389 vectors\n",
      "2024-10-03 22:41:38,154 - INFO - Processed 52000 out of 78389 vectors\n",
      "2024-10-03 22:41:38,370 - INFO - Processed 52500 out of 78389 vectors\n",
      "2024-10-03 22:41:38,595 - INFO - Processed 53000 out of 78389 vectors\n",
      "2024-10-03 22:41:38,811 - INFO - Processed 53500 out of 78389 vectors\n",
      "2024-10-03 22:41:39,043 - INFO - Processed 54000 out of 78389 vectors\n",
      "2024-10-03 22:41:39,260 - INFO - Processed 54500 out of 78389 vectors\n",
      "2024-10-03 22:41:39,477 - INFO - Processed 55000 out of 78389 vectors\n",
      "2024-10-03 22:41:39,694 - INFO - Processed 55500 out of 78389 vectors\n",
      "2024-10-03 22:41:39,921 - INFO - Processed 56000 out of 78389 vectors\n",
      "2024-10-03 22:41:40,140 - INFO - Processed 56500 out of 78389 vectors\n",
      "2024-10-03 22:41:40,362 - INFO - Processed 57000 out of 78389 vectors\n",
      "2024-10-03 22:41:40,577 - INFO - Processed 57500 out of 78389 vectors\n",
      "2024-10-03 22:41:40,790 - INFO - Processed 58000 out of 78389 vectors\n",
      "2024-10-03 22:41:41,007 - INFO - Processed 58500 out of 78389 vectors\n",
      "2024-10-03 22:41:41,238 - INFO - Processed 59000 out of 78389 vectors\n",
      "2024-10-03 22:41:41,459 - INFO - Processed 59500 out of 78389 vectors\n",
      "2024-10-03 22:41:41,675 - INFO - Processed 60000 out of 78389 vectors\n",
      "2024-10-03 22:41:41,906 - INFO - Processed 60500 out of 78389 vectors\n",
      "2024-10-03 22:41:42,127 - INFO - Processed 61000 out of 78389 vectors\n",
      "2024-10-03 22:41:42,341 - INFO - Processed 61500 out of 78389 vectors\n",
      "2024-10-03 22:41:42,561 - INFO - Processed 62000 out of 78389 vectors\n",
      "2024-10-03 22:41:42,784 - INFO - Processed 62500 out of 78389 vectors\n",
      "2024-10-03 22:41:42,997 - INFO - Processed 63000 out of 78389 vectors\n",
      "2024-10-03 22:41:43,219 - INFO - Processed 63500 out of 78389 vectors\n",
      "2024-10-03 22:41:43,434 - INFO - Processed 64000 out of 78389 vectors\n",
      "2024-10-03 22:41:43,648 - INFO - Processed 64500 out of 78389 vectors\n",
      "2024-10-03 22:41:43,867 - INFO - Processed 65000 out of 78389 vectors\n",
      "2024-10-03 22:41:44,085 - INFO - Processed 65500 out of 78389 vectors\n",
      "2024-10-03 22:41:44,317 - INFO - Processed 66000 out of 78389 vectors\n",
      "2024-10-03 22:41:44,535 - INFO - Processed 66500 out of 78389 vectors\n",
      "2024-10-03 22:41:44,754 - INFO - Processed 67000 out of 78389 vectors\n",
      "2024-10-03 22:41:44,993 - INFO - Processed 67500 out of 78389 vectors\n",
      "2024-10-03 22:41:45,217 - INFO - Processed 68000 out of 78389 vectors\n",
      "2024-10-03 22:41:45,441 - INFO - Processed 68500 out of 78389 vectors\n",
      "2024-10-03 22:41:45,654 - INFO - Processed 69000 out of 78389 vectors\n",
      "2024-10-03 22:41:45,873 - INFO - Processed 69500 out of 78389 vectors\n",
      "2024-10-03 22:41:46,093 - INFO - Processed 70000 out of 78389 vectors\n",
      "2024-10-03 22:41:46,324 - INFO - Processed 70500 out of 78389 vectors\n",
      "2024-10-03 22:41:46,545 - INFO - Processed 71000 out of 78389 vectors\n",
      "2024-10-03 22:41:46,768 - INFO - Processed 71500 out of 78389 vectors\n",
      "2024-10-03 22:41:46,997 - INFO - Processed 72000 out of 78389 vectors\n",
      "2024-10-03 22:41:47,224 - INFO - Processed 72500 out of 78389 vectors\n",
      "2024-10-03 22:41:47,439 - INFO - Processed 73000 out of 78389 vectors\n",
      "2024-10-03 22:41:47,661 - INFO - Processed 73500 out of 78389 vectors\n",
      "2024-10-03 22:41:47,887 - INFO - Processed 74000 out of 78389 vectors\n",
      "2024-10-03 22:41:48,113 - INFO - Processed 74500 out of 78389 vectors\n",
      "2024-10-03 22:41:48,333 - INFO - Processed 75000 out of 78389 vectors\n",
      "2024-10-03 22:41:48,548 - INFO - Processed 75500 out of 78389 vectors\n",
      "2024-10-03 22:41:48,774 - INFO - Processed 76000 out of 78389 vectors\n",
      "2024-10-03 22:41:48,993 - INFO - Processed 76500 out of 78389 vectors\n",
      "2024-10-03 22:41:49,207 - INFO - Processed 77000 out of 78389 vectors\n",
      "2024-10-03 22:41:49,422 - INFO - Processed 77500 out of 78389 vectors\n",
      "2024-10-03 22:41:49,639 - INFO - Processed 78000 out of 78389 vectors\n",
      "2024-10-03 22:41:49,852 - INFO - Processed 78389 out of 78389 vectors\n",
      "2024-10-03 22:41:50,037 - INFO - Centroid assignment for vectors completed.\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import numpy as np\n",
    "import logging\n",
    "import json\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Assuming db connection is already established\n",
    "cursor = db.cursor()\n",
    "\n",
    "# Fetch centroids from the database\n",
    "cursor.execute(\"SELECT id, vector FROM centroids\")\n",
    "centroids = cursor.fetchall()\n",
    "\n",
    "# Convert centroids into NumPy arrays\n",
    "centroid_ids = [c[0] for c in centroids]\n",
    "centroid_vectors = np.array([np.array(json.loads(c[1])) for c in centroids])\n",
    "\n",
    "# Fetch all vectors in memory\n",
    "cursor.execute(\"SELECT id, normalized_vector FROM vectors\")\n",
    "vectors = cursor.fetchall()\n",
    "\n",
    "# Process vectors in chunks\n",
    "chunk_size = 500\n",
    "total_vectors = len(vectors)\n",
    "logging.info(f\"Total vectors to process: {total_vectors}\")\n",
    "\n",
    "processed_count = 0\n",
    "updates = {}  # Dictionary to collect vector_id to centroid_id mappings\n",
    "\n",
    "# Normalize centroids (if not already normalized in your data)\n",
    "centroid_magnitudes = np.linalg.norm(centroid_vectors, axis=1)\n",
    "\n",
    "for i in range(0, total_vectors, chunk_size):\n",
    "    chunk = vectors[i:i + chunk_size]\n",
    "\n",
    "    # Extract vector data and convert to NumPy\n",
    "    vector_ids = [v[0] for v in chunk]\n",
    "    vector_data = np.array([np.array(json.loads(v[1])) for v in chunk])\n",
    "\n",
    "    # Normalize vectors (assuming normalized_vector is not already normalized)\n",
    "    vector_magnitudes = np.linalg.norm(vector_data, axis=1)\n",
    "\n",
    "    # Perform bulk cosine similarity calculation\n",
    "    dot_products = np.dot(vector_data, centroid_vectors.T)\n",
    "    cosine_similarities = dot_products / (vector_magnitudes[:, None] * centroid_magnitudes)\n",
    "\n",
    "    # Get the index of the closest centroid for each vector\n",
    "    best_matches = np.argmax(cosine_similarities, axis=1)\n",
    "    \n",
    "    # Collect updates for the batch\n",
    "    for idx, best_match_idx in enumerate(best_matches):\n",
    "        best_centroid_id = centroid_ids[best_match_idx]\n",
    "        vector_id = vector_ids[idx]\n",
    "        updates[vector_id] = best_centroid_id\n",
    "\n",
    "    processed_count += len(chunk)\n",
    "    logging.info(f\"Processed {processed_count} out of {total_vectors} vectors\")\n",
    "\n",
    "    # Perform true batch update for each chunk\n",
    "    if len(updates) >= chunk_size:\n",
    "        update_query = \"UPDATE grant_vector SET centroid_id = CASE \"\n",
    "        update_query += \" \".join([f\"WHEN {vector_id} THEN {centroid_id}\" for vector_id, centroid_id in updates.items()])\n",
    "        update_query += f\" END WHERE vector_id IN ({', '.join(map(str, updates.keys()))})\"\n",
    "        \n",
    "        cursor.execute(update_query)\n",
    "        db.commit()\n",
    "        updates.clear()\n",
    "\n",
    "# Perform remaining updates if any\n",
    "if updates:\n",
    "    update_query = \"UPDATE grant_vector SET centroid_id = CASE \"\n",
    "    update_query += \" \".join([f\"WHEN {vector_id} THEN {centroid_id}\" for vector_id, centroid_id in updates.items()])\n",
    "    update_query += f\" END WHERE vector_id IN ({', '.join(map(str, updates.keys()))})\"\n",
    "    \n",
    "    cursor.execute(update_query)\n",
    "    db.commit()\n",
    "\n",
    "# Commit the changes and close the connection\n",
    "cursor.close()\n",
    "db.close()\n",
    "\n",
    "logging.info(\"Centroid assignment for vectors completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
